# cython:    language_level = 3
# cython:    cdivision      = True
# cython:    boundscheck    = False
# cython:    wraparound     = False

# =============================================================================
# Imports
# =============================================================================

# Numpy
import  numpy as np
cimport numpy as np

# Always include this statement after cimporting numpy, to avoid
# segmentation faults
np.import_array()

from numpy.math cimport INFINITY

# =============================================================================
# Public objects
# =============================================================================

# =============================================================================
# Base splitter
# =============================================================================
cdef class Splitter:
    """
        Base class for splitting the node of a tree.
    """

    def __cinit__(self,
                  Criterion criterion,
                  SIZE_t    max_splits,
                  object    random_state):
        """
            Constructor.
        """
        # Initialize the hyperparameters of the current object
        self.criterion    = criterion
        self.max_splits   = max_splits
        self.random_state = random_state

    cdef void init(self,
                    SIZE_t n_classes):
        pass

    cdef void _init(self,
                    SIZE_t n_classes,
                    SIZE_t n_splits):
        """
            Initialize useful data structures for the partition generated by the splitter.
        """
        # Initialize the number of splits for the current partition
        self.n_splits = n_splits

        # Initialize the impurities
        self.impurity   = INFINITY
        self.impurities = np.zeros(n_splits, dtype = np.float64) 

        # Initialize the thresholds
        self.thresholds        = np.zeros(n_splits + 1, dtype = np.intp)
        self.thresholds_values = np.zeros(n_splits + 1, dtype = np.float64)

        # Initialize the precedences
        self.precedences = np.zeros((n_splits, n_classes, n_classes, 2), dtype = np.float64)

        # Initialize the consensus
        self.consensus = np.zeros((n_splits, n_classes), dtype = np.intp)

    cdef void partition_parameters(self,
                                   DTYPE_t[:]          X,
                                   SIZE_t              att,
                                   DTYPE_t[:, :]       Y,
                                   DTYPE_t[:, :, :]    gbl_precedences,
                                   DTYPE_t[:, :, :, :] ind_precedences,
                                   DTYPE_t[:, :, :]    ind_pair_order_matrices,
                                   DTYPE_t[:]          sample_weight,
                                   SIZE_t[:]           sorted_indexes) nogil:
        pass

    cdef void _subtract_precedences(self,
                                    DTYPE_t[:, :, :] first_operand,
                                    DTYPE_t[:, :, :] second_operand,
                                    DTYPE_t[:, :, :] output_operand,
                                    DTYPE_t          sample_weight) nogil:
        """
            Substract the second operand precedences matrix to the first operand precedences one setting the content into the output one according to the
            given weight of the second operand.
        """
        # Initialize some values from the input arrays
        cdef SIZE_t n_classes = first_operand.shape[0]

        # Define the indexes
        cdef SIZE_t f_class
        cdef SIZE_t s_class

        # Iterate through the classes to obtain the new precedences matrix
        for f_class in range(n_classes):
            for s_class in range(n_classes):
                output_operand[f_class, s_class, 0] = first_operand[f_class, s_class, 0] - sample_weight * second_operand[f_class, s_class, 0]
                output_operand[f_class, s_class, 1] = first_operand[f_class, s_class, 1] - sample_weight * second_operand[f_class, s_class, 1]

    cdef void _add_precedences(self,
                               DTYPE_t[:, :, :] first_operand,
                               DTYPE_t[:, :, :] second_operand,
                               DTYPE_t[:, :, :] output_operand,
                               DTYPE_t          sample_weight) nogil:
        """
            Substract the second operand precedences matrix to the first operand precedences one setting the content into the output one according to the
            given weight of the second operand.
        """
        # Initialize some values from the input arrays
        cdef SIZE_t n_classes = first_operand.shape[0]

        # Define the indexes
        cdef SIZE_t f_class
        cdef SIZE_t s_class

        # Iterate through the classes to obtain the new precedences matrix
        for f_class in range(n_classes):
            for s_class in range(n_classes):
                output_operand[f_class, s_class, 0] = first_operand[f_class, s_class, 0] + sample_weight * second_operand[f_class, s_class, 0]
                output_operand[f_class, s_class, 1] = first_operand[f_class, s_class, 1] + sample_weight * second_operand[f_class, s_class, 1]

    cdef void split_indexes(self,
                            SIZE_t[:, :] sorted_indexes):
        """
            Split the indexes according to the given attribute and thresholds.
        """
        # Initialize some values from the input arrays
        cdef SIZE_t n_samples  = sorted_indexes[0].shape[0]
        cdef SIZE_t n_features = sorted_indexes.shape[0]

        # Define some values to be employed
        cdef INDEXES_t  test_elements
        cdef UINT8_t[:] matrix

        # Define the indexes
        cdef SIZE_t split
        cdef SIZE_t att
        cdef SIZE_t sample
        cdef SIZE_t index

        # Initialize the list of the sorted indexes
        self.sorted_indexes = list()

        # Initialize the boolean matrix, just once,
        # because it is possible to override it
        # without needed to create several ones
        matrix = np.zeros(n_samples, dtype = np.uint8)

        # Obtain the sorted indexes for each child
        # going through each attribute and checking
        # the elements that must be keep the the current child
        for split in range(self.n_splits):
            # Obtain the set with the elements to be kept for the current child,
            # previously clearing the contents
            test_elements.clear()
            self._memory_view_to_set(test_elements     = sorted_indexes[self.att][self.thresholds[split]:self.thresholds[split + 1]],
                                     test_elements_set = &test_elements)
            # Initialize the NumPy array for the inner memory view of the sorted indexes
            self.sorted_indexes.append(np.zeros((n_features, test_elements.size()), dtype = np.intp))
            # Once obtained the set, compute the corresponding boolean matrix
            for att in range(n_features):
                # Compute the boolean matrix to apply the indexing
                self._in1d(element = sorted_indexes[att], test_elements = &test_elements, matrix = matrix)
                # Initialize the counter to know the index inside the inner data structure with the
                # sorted indexes for the child and attribute
                index = 0
                # Insert the elements into the memory view, checking the contents with the
                # compute boolean matrix
                for sample in range(n_samples):
                    if matrix[sample]:
                        self.sorted_indexes[split][att, index] = sorted_indexes[att, sample]
                        index += 1

    cdef void _in1d(self,
                    SIZE_t[:]  element,
                    INDEXES_t  *test_elements,
                    UINT8_t[:] matrix) nogil:
        """
            Efficient version of the method "in1d" of NumPy for the current problem.
        """
        # Initialize some values from the input arrays
        cdef SIZE_t n_samples = element.shape[0]

        # Define the indexes
        cdef SIZE_t sample
        cdef SIZE_t index

        # Iterate all the elements to test whether it must be kept or removed
        for sample in range(n_samples):
            # Obtain the index
            index = element[sample]
            # If the index is in the set, keep it
            if test_elements.find(index) != test_elements.end():
                matrix[sample] = True
            # Otherwise, remove it
            else:
                matrix[sample] = False

    cdef void _memory_view_to_set(self,
                                  SIZE_t[:] test_elements,
                                  INDEXES_t *test_elements_set) nogil:
        """
            Introduce the elements of a memory view into an unordered set.
        """
        # Initialize some values from the input arrays
        cdef SIZE_t n_samples = test_elements.shape[0]

        # Define the indexes
        cdef SIZE_t sample

        # Introduce all the elements into the unordered set
        for sample in range(n_samples):
            test_elements_set.insert(test_elements[sample])

# =============================================================================
# Binary splitter
# =============================================================================
cdef class BinarySplitter(Splitter):
    """
        Class for splitting the node of a tree selecting the best threshold for each attribute.
    """

    cdef void init(self,
                   SIZE_t n_classes):
        """
            In this case, initializes two auxiliar arrays, one for the precedences
            matrices and another one for the consensus bucket orders, to avoid the
            creation of multiple arrays.

            HACKISH: MANUALLY SET THE NUMBER OF SPLITS TO 2, EVEN IF A DIFFERENT
            NUMBER HAS BEEN SPECIFIED.
        """
        # Call to the method of the parent
        Splitter._init(self, n_classes = n_classes, n_splits = 2)

        # Initialize the auxiliar precedences matrices and consensus bucket orders
        self.aux_precedences = np.zeros((2, n_classes, n_classes, 2), dtype = np.float64)
        self.aux_consensus   = np.zeros((2, n_classes),               dtype = np.intp)

    cdef void partition_parameters(self,
                                   DTYPE_t[:]          X,
                                   SIZE_t              att,
                                   DTYPE_t[:, :]       Y,
                                   DTYPE_t[:, :, :]    gbl_precedences,
                                   DTYPE_t[:, :, :, :] ind_precedences,
                                   DTYPE_t[:, :, :]    ind_pair_order_matrices,
                                   DTYPE_t[:]          sample_weight,
                                   SIZE_t[:]           sorted_indexes) nogil:
        """
            Obtain the best parameters for the current partition.
        """
        # Initialize some values from the input arrays
        cdef SIZE_t n_samples = sorted_indexes.shape[0]

        # Define some values to be employed

        # Impurity
        cdef DTYPE_t impurity
        cdef DTYPE_t proportion_left
        cdef DTYPE_t impurity_left
        cdef DTYPE_t proportion_right
        cdef DTYPE_t impurity_right
  
        # Precedences
        cdef DTYPE_t[:, :, :] precedences_left
        cdef DTYPE_t[:, :, :] precedences_right

        # Consensus bucket orders
        cdef SIZE_t[:] consensus_left
        cdef SIZE_t[:] consensus_right

        # Define the indexes
        cdef SIZE_t sample

        # IMPORTANT: REINITIALIZE THE AUXILIAR DATA STRUCTURES
        self.aux_precedences[:] = 0
        self.aux_consensus[:]   = 0

        # Initialize the left and right precedences matrices from the auxiliar ones
        precedences_left  = self.aux_precedences[0]
        precedences_right = self.aux_precedences[1]

        # Initialize the left and right consensus bucket orders
        consensus_left  = self.aux_consensus[0]
        consensus_right = self.aux_consensus[1]

        # Add to precedences left, the precedences of the first sample
        self._add_precedences(first_operand  = precedences_left,
                              second_operand = ind_precedences[sorted_indexes[0]], 
                              output_operand = precedences_left,
                              sample_weight  = sample_weight[sorted_indexes[0]])

        # Subtract to precedences, the precedences of the first sample
        self._subtract_precedences(first_operand  = gbl_precedences,
                                   second_operand = precedences_left,
                                   output_operand = precedences_right,
                                   sample_weight  = sample_weight[sorted_indexes[0]])

        # Look for all possible thresholds
        for sample in range(1, n_samples):
            # Found one possible split
            if X[sorted_indexes[sample - 1]] != X[sorted_indexes[sample]]:
                # Obtain the impurity and bucket order for both sides of the split
                impurity_left = self.criterion.node_impurity_consensus(precedences         = precedences_left,
                                                                       pair_order_matrices = ind_pair_order_matrices,
                                                                       consensus           = consensus_left,
                                                                       sample_weight       = sample_weight,
                                                                       sorted_indexes      = sorted_indexes,
                                                                       start_index         = 0,
                                                                       end_index           = sample)

                impurity_right = self.criterion.node_impurity_consensus(precedences         = precedences_right,
                                                                        pair_order_matrices = ind_pair_order_matrices,
                                                                        consensus           = consensus_right,
                                                                        sample_weight       = sample_weight,
                                                                        sorted_indexes      = sorted_indexes,
                                                                        start_index         = sample,
                                                                        end_index           = n_samples)

                # Weight them
                proportion_left  = ((float(sample)) / (float(n_samples)))
                proportion_right = 1.0 - proportion_left
                impurity         = proportion_left * impurity_left + proportion_right * impurity_right

                # Check if the current threshold is better than the one previously found
                # If it is, change the parameters
                if impurity < self.impurity:
                    self.att                  = att
                    self.impurity             = impurity
                    self.impurities[0]        = impurity_left
                    self.impurities[1]        = impurity_right
                    self.thresholds[0]        = 0
                    self.thresholds[1]        = sample
                    self.thresholds[2]        = n_samples
                    self.thresholds_values[0] = -INFINITY
                    self.thresholds_values[1] = (X[sorted_indexes[sample - 1]] + X[sorted_indexes[sample]]) / 2
                    self.thresholds_values[2] = INFINITY
                    self.precedences[0, :]    = precedences_left
                    self.precedences[1, :]    = precedences_right
                    self.consensus[0, :]      = consensus_left
                    self.consensus[1, :]      = consensus_right

            # Add to precedences left, the precedences of the first sample
            self._add_precedences(first_operand  = precedences_left,
                                  second_operand = ind_precedences[sorted_indexes[sample]],
                                  output_operand = precedences_left,
                                  sample_weight  = sample_weight[sorted_indexes[sample]])

            # Subtract to precedences, the precedences of the first sample
            self._subtract_precedences(first_operand  = precedences_right,
                                       second_operand = ind_precedences[sorted_indexes[sample]],
                                       output_operand = precedences_right,
                                       sample_weight  = sample_weight[sorted_indexes[sample]])
